{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lOWg6WDGZIk6"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "import pickle\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the dataset"
      ],
      "metadata": {
        "id": "rmAZpbjwlBcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def feature_extraction_steps(file_path,directory_path):\n",
        "  df_file = pd.read_csv(os.path.join(directory_path, file_path),header=1,skip_blank_lines=True,skiprows =[0,1,2,3])\n",
        "  df_file_info = pd.read_csv(os.path.join(directory_path, file_path),header=None,nrows=4,skip_blank_lines=True)\n",
        "  activity = df_file_info.iloc[2,1].lower()\n",
        "  activity = 'run' if 'run' in activity else 'walk'\n",
        "  actucal_steps = df_file_info.iloc[3,1]\n",
        "\n",
        "  norm = []\n",
        "  cols = df_file.columns\n",
        "  for i, row in df_file.iterrows():\n",
        "    x = float(row[cols[1]])\n",
        "    y = float(row[cols[2]])\n",
        "    z = float(row[cols[3]])\n",
        "    norm.append((x**2 + y**2 + z**2) ** 0.5)\n",
        "  norm = np.array(norm)\n",
        "  df_file['norm'] = norm\n",
        "  features = []\n",
        "  cols = df_file.columns\n",
        "  for col_name in [cols[0],cols[3],cols[4]]:\n",
        "    vals = df_file[col_name].values\n",
        "    vals_lag = vals-(np.append(vals[1:],0))\n",
        "    vals_2lag = vals-(np.append(vals[2:],[0,0]))\n",
        "    vals_3lag = vals-(np.append(vals[3:],[0,0,0]))\n",
        "    features.append(vals.mean())\n",
        "    features.append(vals.std())\n",
        "    features.append(vals.max())\n",
        "    features.append(vals.min())\n",
        "    features.append(vals_lag.mean())\n",
        "    features.append(vals_lag.std())\n",
        "    features.append(vals_lag.max())\n",
        "    features.append(vals_lag.min())\n",
        "    features.append(vals_2lag.mean())\n",
        "    features.append(vals_2lag.std())\n",
        "    features.append(vals_2lag.max())\n",
        "    features.append(vals_2lag.min())\n",
        "  fft = np.fft.fft(norm)\n",
        "  time_vals = df_file[cols[0]].values\n",
        "  dt = time_vals[1]-time_vals[0]\n",
        "  n = len(norm)\n",
        "  frequencies = np.fft.fftfreq(n, dt)\n",
        "  features.append(len(time_vals))\n",
        "  features.append(frequencies.mean())\n",
        "  features.append(frequencies.std())\n",
        "  features.append(frequencies.max())\n",
        "  features.append(frequencies.min())\n",
        "  features = np.array(features)\n",
        "  return features,actucal_steps,activity\n",
        "\n",
        "\n",
        "def create_steps_dataset(directory_files):\n",
        "  X_run = []\n",
        "  y_run = []\n",
        "  X_walk = []\n",
        "  y_walk = []\n",
        "  for path in directory_files:\n",
        "    try:\n",
        "      cur_X,cur_y,activity = feature_extraction_steps(path,directory_path)\n",
        "      if activity == 'run':\n",
        "        X_run.append(cur_X)\n",
        "        y_run.append(cur_y)\n",
        "      else:\n",
        "        X_walk.append(cur_X)\n",
        "        y_walk.append(cur_y)\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "      continue\n",
        "  X_run = np.stack(X_run)\n",
        "  y_run = np.array(y_run,dtype=object)\n",
        "  X_run = np.nan_to_num(X_run, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "  X_run = np.array(X_run,dtype=object)\n",
        "\n",
        "  X_walk = np.stack(X_walk)\n",
        "  y_walk = np.array(y_walk,dtype=object)\n",
        "  X_walk = np.nan_to_num(X_walk, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "  X_walk = np.array(X_walk,dtype=object)\n",
        "  return X_run,y_run,X_walk,y_walk\n",
        "\n",
        "\n",
        "\n",
        "def feature_extraction_activity(file_path,directory_path):\n",
        "  df_file = pd.read_csv(os.path.join(directory_path, file_path),header=1,skip_blank_lines=True,skiprows =[0,1,2,3])\n",
        "  df_file_info = pd.read_csv(os.path.join(directory_path, file_path),header=None,nrows=4,skip_blank_lines=True)\n",
        "  activity = 1 if 'run' in df_file_info.iloc[2,1].lower() else 0\n",
        "\n",
        "  norm = []\n",
        "  cols = df_file.columns\n",
        "  for i, row in df_file.iterrows():\n",
        "    x = float(row[cols[1]])\n",
        "    y = float(row[cols[2]])\n",
        "    z = float(row[cols[3]])\n",
        "    norm.append((x**2 + y**2 + z**2) ** 0.5)\n",
        "  norm = np.array(norm)\n",
        "  df_file['norm'] = norm\n",
        "  features = []\n",
        "  cols = df_file.columns\n",
        "  for col_name in [cols[0],cols[3],cols[4]]:\n",
        "    vals = df_file[col_name].values\n",
        "    vals_lag = vals-(np.append(vals[1:],0))\n",
        "    vals_2lag = vals-(np.append(vals[2:],[0,0]))\n",
        "    vals_3lag = vals-(np.append(vals[3:],[0,0,0]))\n",
        "    features.append(vals.mean())\n",
        "    features.append(vals.std())\n",
        "    features.append(vals.max())\n",
        "    features.append(vals.min())\n",
        "    features.append(vals_lag.mean())\n",
        "    features.append(vals_lag.std())\n",
        "    features.append(vals_lag.max())\n",
        "    features.append(vals_lag.min())\n",
        "    features.append(vals_2lag.mean())\n",
        "    features.append(vals_2lag.std())\n",
        "    features.append(vals_2lag.max())\n",
        "    features.append(vals_2lag.min())\n",
        "  fft = np.fft.fft(norm)\n",
        "  time_vals = df_file[cols[0]].values\n",
        "  dt = time_vals[1]-time_vals[0]\n",
        "  n = len(norm)\n",
        "  frequencies = np.fft.fftfreq(n, dt)\n",
        "  features.append(len(time_vals))\n",
        "  features.append(frequencies.mean())\n",
        "  features.append(frequencies.std())\n",
        "  features.append(frequencies.max())\n",
        "  features.append(frequencies.min())\n",
        "  features = np.array(features)\n",
        "  return features,activity\n",
        "\n",
        "def create_activity_dataset(directory_files):\n",
        "  X = []\n",
        "  y = []\n",
        "  for path in directory_files:\n",
        "    try:\n",
        "      cur_X,cur_y = feature_extraction_activity(path,directory_path)\n",
        "      X.append(cur_X)\n",
        "      y.append(cur_y)\n",
        "    except Exception as error:\n",
        "      print(error)\n",
        "      continue\n",
        "  X = np.stack(X)\n",
        "  y = np.array(y)\n",
        "  X = np.nan_to_num(X, copy=True, nan=0.0, posinf=None, neginf=None)\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "ueIkUXwpZV6l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = \"/content/data\"\n",
        "directory_files = os.listdir(directory_path)"
      ],
      "metadata": {
        "id": "9sjGvmvpZiFi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose best Random Forest hyper-parameters and train"
      ],
      "metadata": {
        "id": "T2Os_f0LlIAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = create_activity_dataset(directory_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGKpeIdJoFIh",
        "outputId": "a5d9b322-cc83-46a5-aa06-059db923fe60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "could not convert string to float: 'walk_4_1.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for criterion in [\"gini\", \"entropy\", \"log_loss\"]:\n",
        "  for max_depth in [20,50,100]:\n",
        "    for min_samples_split in [2,3,4]:\n",
        "      clf = RandomForestClassifier(n_estimators=1000, random_state=0,criterion=criterion,max_depth=max_depth,min_samples_split=min_samples_split)\n",
        "      scores = cross_val_score(clf, X, y, cv=5)\n",
        "      print(f\"Score:{scores.mean()},criterion = {criterion}, max_depth = {max_depth}, min_samples = {min_samples_split}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3-IaBhMe3s-",
        "outputId": "95b1ae5a-fe5f-4cb6-d2a0-8cef48774247"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score:0.9486274509803921,criterion = gini, max_depth = 20, min_samples = 2\n",
            "Score:0.9446274509803922,criterion = gini, max_depth = 20, min_samples = 3\n",
            "Score:0.9406274509803921,criterion = gini, max_depth = 20, min_samples = 4\n",
            "Score:0.9486274509803921,criterion = gini, max_depth = 50, min_samples = 2\n",
            "Score:0.9446274509803922,criterion = gini, max_depth = 50, min_samples = 3\n",
            "Score:0.9406274509803921,criterion = gini, max_depth = 50, min_samples = 4\n",
            "Score:0.9486274509803921,criterion = gini, max_depth = 100, min_samples = 2\n",
            "Score:0.9446274509803922,criterion = gini, max_depth = 100, min_samples = 3\n",
            "Score:0.9406274509803921,criterion = gini, max_depth = 100, min_samples = 4\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 20, min_samples = 2\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 20, min_samples = 3\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 20, min_samples = 4\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 50, min_samples = 2\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 50, min_samples = 3\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 50, min_samples = 4\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 100, min_samples = 2\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 100, min_samples = 3\n",
            "Score:0.9485490196078432,criterion = entropy, max_depth = 100, min_samples = 4\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 20, min_samples = 2\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 20, min_samples = 3\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 20, min_samples = 4\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 50, min_samples = 2\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 50, min_samples = 3\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 50, min_samples = 4\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 100, min_samples = 2\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 100, min_samples = 3\n",
            "Score:0.9485490196078432,criterion = log_loss, max_depth = 100, min_samples = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=1000, random_state=0,criterion=\"gini\",max_depth=100,min_samples_split=2)\n",
        "clf.fit(X, y)\n",
        "pickle.dump(clf, open('random_forest_model.pkl', 'wb'))\n",
        "activity_model = pickle.load(open('random_forest_model.pkl', 'rb'))\n",
        "score = activity_model.score(X,y)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBCr0Kg-chIA",
        "outputId": "e8b3bee2-988b-4808-d84c-0f62f858e18f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose best XBBRegressor hyper-parameters for walk and train"
      ],
      "metadata": {
        "id": "F6FYxLHxlUCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_run,y_run,X_walk,y_walk = create_steps_dataset(directory_files)"
      ],
      "metadata": {
        "id": "TCWIEflXoDpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29316440-f0e2-48c9-afc5-2436ce846d59"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "could not convert string to float: 'walk_4_1.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_walk,y_walk\n",
        "for n_estimators in [1000,1500,2000]:\n",
        "  for max_depth in [75,100,125,150]:\n",
        "    for learning_rate in [None,0.004,0.005,0.006,0.007]:\n",
        "      scores = []\n",
        "      for i in [1,2,3,4,5]:\n",
        "        model = XGBRegressor(n_estimators=n_estimators,max_depth= max_depth,learning_rate=learning_rate,booster=\"gbtree\",objective ='reg:squarederror')\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random.randint(3, 15))\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test).round()\n",
        "        scores.append(mean_squared_error(predictions,y_test,squared=False))\n",
        "      print(f\"Score: {np.array(scores).mean()}, n_estimators: {n_estimators},max_depth: {max_depth},learning_rate: {learning_rate}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-yDyEZDiTP_",
        "outputId": "15b5d161-0781-429c-d3d2-1fd7af8acabd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 15.306304697557803, n_estimators: 1000,max_depth: 75,learning_rate: None\n",
            "Score: 17.71984338442169, n_estimators: 1000,max_depth: 75,learning_rate: 0.004\n",
            "Score: 15.58774958819338, n_estimators: 1000,max_depth: 75,learning_rate: 0.005\n",
            "Score: 17.46859156950994, n_estimators: 1000,max_depth: 75,learning_rate: 0.006\n",
            "Score: 15.595789565671675, n_estimators: 1000,max_depth: 75,learning_rate: 0.007\n",
            "Score: 15.784583654603882, n_estimators: 1000,max_depth: 100,learning_rate: None\n",
            "Score: 15.245690151119433, n_estimators: 1000,max_depth: 100,learning_rate: 0.004\n",
            "Score: 17.032198872660743, n_estimators: 1000,max_depth: 100,learning_rate: 0.005\n",
            "Score: 17.93587178296649, n_estimators: 1000,max_depth: 100,learning_rate: 0.006\n",
            "Score: 15.656918454553738, n_estimators: 1000,max_depth: 100,learning_rate: 0.007\n",
            "Score: 18.66464304562607, n_estimators: 1000,max_depth: 125,learning_rate: None\n",
            "Score: 19.126801346777754, n_estimators: 1000,max_depth: 125,learning_rate: 0.004\n",
            "Score: 13.821895216576902, n_estimators: 1000,max_depth: 125,learning_rate: 0.005\n",
            "Score: 13.552280190855004, n_estimators: 1000,max_depth: 125,learning_rate: 0.006\n",
            "Score: 17.745104679999564, n_estimators: 1000,max_depth: 125,learning_rate: 0.007\n",
            "Score: 16.78307625834281, n_estimators: 1000,max_depth: 150,learning_rate: None\n",
            "Score: 18.3221713169114, n_estimators: 1000,max_depth: 150,learning_rate: 0.004\n",
            "Score: 15.78549543634001, n_estimators: 1000,max_depth: 150,learning_rate: 0.005\n",
            "Score: 16.349730137141414, n_estimators: 1000,max_depth: 150,learning_rate: 0.006\n",
            "Score: 15.307975643207428, n_estimators: 1000,max_depth: 150,learning_rate: 0.007\n",
            "Score: 12.587811522638756, n_estimators: 1500,max_depth: 75,learning_rate: None\n",
            "Score: 13.699095562938066, n_estimators: 1500,max_depth: 75,learning_rate: 0.004\n",
            "Score: 15.213741646274382, n_estimators: 1500,max_depth: 75,learning_rate: 0.005\n",
            "Score: 13.65791902521482, n_estimators: 1500,max_depth: 75,learning_rate: 0.006\n",
            "Score: 15.021032833190953, n_estimators: 1500,max_depth: 75,learning_rate: 0.007\n",
            "Score: 14.236112949975155, n_estimators: 1500,max_depth: 100,learning_rate: None\n",
            "Score: 16.92203888979987, n_estimators: 1500,max_depth: 100,learning_rate: 0.004\n",
            "Score: 14.353083082313518, n_estimators: 1500,max_depth: 100,learning_rate: 0.005\n",
            "Score: 19.26625632139896, n_estimators: 1500,max_depth: 100,learning_rate: 0.006\n",
            "Score: 13.8031306908235, n_estimators: 1500,max_depth: 100,learning_rate: 0.007\n",
            "Score: 16.741360269158285, n_estimators: 1500,max_depth: 125,learning_rate: None\n",
            "Score: 12.578301824705365, n_estimators: 1500,max_depth: 125,learning_rate: 0.004\n",
            "Score: 14.165745958253883, n_estimators: 1500,max_depth: 125,learning_rate: 0.005\n",
            "Score: 16.26448175844721, n_estimators: 1500,max_depth: 125,learning_rate: 0.006\n",
            "Score: 22.537188078578435, n_estimators: 1500,max_depth: 125,learning_rate: 0.007\n",
            "Score: 13.492048779148337, n_estimators: 1500,max_depth: 150,learning_rate: None\n",
            "Score: 14.374092704907401, n_estimators: 1500,max_depth: 150,learning_rate: 0.004\n",
            "Score: 13.018238207342208, n_estimators: 1500,max_depth: 150,learning_rate: 0.005\n",
            "Score: 12.997152344030876, n_estimators: 1500,max_depth: 150,learning_rate: 0.006\n",
            "Score: 14.949087967528872, n_estimators: 1500,max_depth: 150,learning_rate: 0.007\n",
            "Score: 14.384421997110682, n_estimators: 2000,max_depth: 75,learning_rate: None\n",
            "Score: 19.085718542758244, n_estimators: 2000,max_depth: 75,learning_rate: 0.004\n",
            "Score: 14.544691563582859, n_estimators: 2000,max_depth: 75,learning_rate: 0.005\n",
            "Score: 15.649444490995368, n_estimators: 2000,max_depth: 75,learning_rate: 0.006\n",
            "Score: 15.85936343323454, n_estimators: 2000,max_depth: 75,learning_rate: 0.007\n",
            "Score: 13.796993232565644, n_estimators: 2000,max_depth: 100,learning_rate: None\n",
            "Score: 16.470894280337692, n_estimators: 2000,max_depth: 100,learning_rate: 0.004\n",
            "Score: 15.113858278706834, n_estimators: 2000,max_depth: 100,learning_rate: 0.005\n",
            "Score: 13.504523654088104, n_estimators: 2000,max_depth: 100,learning_rate: 0.006\n",
            "Score: 17.532706789223973, n_estimators: 2000,max_depth: 100,learning_rate: 0.007\n",
            "Score: 17.475113065627802, n_estimators: 2000,max_depth: 125,learning_rate: None\n",
            "Score: 16.00918894071974, n_estimators: 2000,max_depth: 125,learning_rate: 0.004\n",
            "Score: 15.539027955930631, n_estimators: 2000,max_depth: 125,learning_rate: 0.005\n",
            "Score: 14.337455192471506, n_estimators: 2000,max_depth: 125,learning_rate: 0.006\n",
            "Score: 16.743964173594676, n_estimators: 2000,max_depth: 125,learning_rate: 0.007\n",
            "Score: 14.10861957968007, n_estimators: 2000,max_depth: 150,learning_rate: None\n",
            "Score: 17.124745999096096, n_estimators: 2000,max_depth: 150,learning_rate: 0.004\n",
            "Score: 17.050389413367704, n_estimators: 2000,max_depth: 150,learning_rate: 0.005\n",
            "Score: 14.38453589646046, n_estimators: 2000,max_depth: 150,learning_rate: 0.006\n",
            "Score: 14.498314373404355, n_estimators: 2000,max_depth: 150,learning_rate: 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best score\n",
        "model = XGBRegressor(n_estimators=1500,max_depth= 100,booster=\"gbtree\",objective ='reg:squarederror')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test).round()\n",
        "print(f\"RMSE: {mean_squared_error(predictions,y_test,squared=False)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l2Hzq0Um2zZ",
        "outputId": "97c63db7-b38a-48af-e431-f72a6b40ba82"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 9.97882373213011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_walk,y_walk\n",
        "model = XGBRegressor(n_estimators=1500,max_depth= 100,booster=\"gbtree\",objective ='reg:squarederror')\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "pickle.dump(model, open('steps_walk_model.pkl', 'wb'))\n",
        "walk_model = pickle.load(open('steps_walk_model.pkl', 'rb'))\n",
        "predictions = walk_model.predict(X).round()\n",
        "mean_squared_error(predictions,y,squared=False)"
      ],
      "metadata": {
        "id": "AtT4_0OsZ_Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637c337a-fa30-4d2e-915d-1df034778cb1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose best XBBRegressor hyper-parameters for run and train"
      ],
      "metadata": {
        "id": "g4j027hllex8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_run,y_run\n",
        "for n_estimators in [1000,1500,2000]:\n",
        "  for max_depth in [None,75,100,125,150]:\n",
        "    for learning_rate in [None,0.004,0.005,0.006,0.007]:\n",
        "      scores = []\n",
        "      for i in [1,2,3,4,5]:\n",
        "        model = XGBRegressor(n_estimators=n_estimators,max_depth= max_depth,learning_rate=learning_rate,booster=\"gbtree\",objective ='reg:squarederror')\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random.randint(3, 15))\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions = model.predict(X_test).round()\n",
        "        scores.append(mean_squared_error(predictions,y_test,squared=False))\n",
        "      print(f\"Score: {np.array(scores).mean()}, n_estimators: {n_estimators},max_depth: {max_depth},learning_rate: {learning_rate}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsT4-H6lkld6",
        "outputId": "bee3dc97-daf1-4730-8fe7-97a1051c3dfd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 13.636031945015912, n_estimators: 1000,max_depth: None,learning_rate: None\n",
            "Score: 15.595560805482773, n_estimators: 1000,max_depth: None,learning_rate: 0.004\n",
            "Score: 14.686540113111004, n_estimators: 1000,max_depth: None,learning_rate: 0.005\n",
            "Score: 14.110869816364783, n_estimators: 1000,max_depth: None,learning_rate: 0.006\n",
            "Score: 12.475951908765031, n_estimators: 1000,max_depth: None,learning_rate: 0.007\n",
            "Score: 14.673853523284862, n_estimators: 1000,max_depth: 75,learning_rate: None\n",
            "Score: 16.269023255360075, n_estimators: 1000,max_depth: 75,learning_rate: 0.004\n",
            "Score: 12.57642652306238, n_estimators: 1000,max_depth: 75,learning_rate: 0.005\n",
            "Score: 12.72792696848945, n_estimators: 1000,max_depth: 75,learning_rate: 0.006\n",
            "Score: 17.092649100140655, n_estimators: 1000,max_depth: 75,learning_rate: 0.007\n",
            "Score: 16.257272159402035, n_estimators: 1000,max_depth: 100,learning_rate: None\n",
            "Score: 12.592260715969521, n_estimators: 1000,max_depth: 100,learning_rate: 0.004\n",
            "Score: 13.733195704068402, n_estimators: 1000,max_depth: 100,learning_rate: 0.005\n",
            "Score: 13.40777717737655, n_estimators: 1000,max_depth: 100,learning_rate: 0.006\n",
            "Score: 13.75684011626899, n_estimators: 1000,max_depth: 100,learning_rate: 0.007\n",
            "Score: 16.744945740992794, n_estimators: 1000,max_depth: 125,learning_rate: None\n",
            "Score: 12.846093904641645, n_estimators: 1000,max_depth: 125,learning_rate: 0.004\n",
            "Score: 13.375822243886365, n_estimators: 1000,max_depth: 125,learning_rate: 0.005\n",
            "Score: 16.526327048126706, n_estimators: 1000,max_depth: 125,learning_rate: 0.006\n",
            "Score: 15.36631042670705, n_estimators: 1000,max_depth: 125,learning_rate: 0.007\n",
            "Score: 15.33132451297063, n_estimators: 1000,max_depth: 150,learning_rate: None\n",
            "Score: 15.901492882917903, n_estimators: 1000,max_depth: 150,learning_rate: 0.004\n",
            "Score: 14.416475388691538, n_estimators: 1000,max_depth: 150,learning_rate: 0.005\n",
            "Score: 15.318079059283093, n_estimators: 1000,max_depth: 150,learning_rate: 0.006\n",
            "Score: 12.943800075266441, n_estimators: 1000,max_depth: 150,learning_rate: 0.007\n",
            "Score: 15.713152160555243, n_estimators: 1500,max_depth: None,learning_rate: None\n",
            "Score: 11.74920866123947, n_estimators: 1500,max_depth: None,learning_rate: 0.004\n",
            "Score: 14.120907093304357, n_estimators: 1500,max_depth: None,learning_rate: 0.005\n",
            "Score: 12.80764809874564, n_estimators: 1500,max_depth: None,learning_rate: 0.006\n",
            "Score: 13.114052407951444, n_estimators: 1500,max_depth: None,learning_rate: 0.007\n",
            "Score: 16.542875926456798, n_estimators: 1500,max_depth: 75,learning_rate: None\n",
            "Score: 12.150502550467362, n_estimators: 1500,max_depth: 75,learning_rate: 0.004\n",
            "Score: 13.44585900096261, n_estimators: 1500,max_depth: 75,learning_rate: 0.005\n",
            "Score: 16.07811176005282, n_estimators: 1500,max_depth: 75,learning_rate: 0.006\n",
            "Score: 17.482123951161544, n_estimators: 1500,max_depth: 75,learning_rate: 0.007\n",
            "Score: 15.649689422650557, n_estimators: 1500,max_depth: 100,learning_rate: None\n",
            "Score: 14.881347365240359, n_estimators: 1500,max_depth: 100,learning_rate: 0.004\n",
            "Score: 12.938550604716927, n_estimators: 1500,max_depth: 100,learning_rate: 0.005\n",
            "Score: 12.394575253726881, n_estimators: 1500,max_depth: 100,learning_rate: 0.006\n",
            "Score: 15.4607727433528, n_estimators: 1500,max_depth: 100,learning_rate: 0.007\n",
            "Score: 16.835267774724485, n_estimators: 1500,max_depth: 125,learning_rate: None\n",
            "Score: 14.98693829414471, n_estimators: 1500,max_depth: 125,learning_rate: 0.004\n",
            "Score: 13.31184936633698, n_estimators: 1500,max_depth: 125,learning_rate: 0.005\n",
            "Score: 15.805032894109221, n_estimators: 1500,max_depth: 125,learning_rate: 0.006\n",
            "Score: 16.107760287348846, n_estimators: 1500,max_depth: 125,learning_rate: 0.007\n",
            "Score: 14.414682765741583, n_estimators: 1500,max_depth: 150,learning_rate: None\n",
            "Score: 14.576404295717515, n_estimators: 1500,max_depth: 150,learning_rate: 0.004\n",
            "Score: 12.902172684277634, n_estimators: 1500,max_depth: 150,learning_rate: 0.005\n",
            "Score: 12.998208795944965, n_estimators: 1500,max_depth: 150,learning_rate: 0.006\n",
            "Score: 16.419386101113883, n_estimators: 1500,max_depth: 150,learning_rate: 0.007\n",
            "Score: 16.30428290552088, n_estimators: 2000,max_depth: None,learning_rate: None\n",
            "Score: 12.273224731667721, n_estimators: 2000,max_depth: None,learning_rate: 0.004\n",
            "Score: 15.225769578213686, n_estimators: 2000,max_depth: None,learning_rate: 0.005\n",
            "Score: 16.00279876108575, n_estimators: 2000,max_depth: None,learning_rate: 0.006\n",
            "Score: 13.706006893432374, n_estimators: 2000,max_depth: None,learning_rate: 0.007\n",
            "Score: 14.19064549122199, n_estimators: 2000,max_depth: 75,learning_rate: None\n",
            "Score: 12.732191478560686, n_estimators: 2000,max_depth: 75,learning_rate: 0.004\n",
            "Score: 14.53966788740667, n_estimators: 2000,max_depth: 75,learning_rate: 0.005\n",
            "Score: 14.185370816347518, n_estimators: 2000,max_depth: 75,learning_rate: 0.006\n",
            "Score: 15.921160817663704, n_estimators: 2000,max_depth: 75,learning_rate: 0.007\n",
            "Score: 14.190707787272036, n_estimators: 2000,max_depth: 100,learning_rate: None\n",
            "Score: 14.611123731254144, n_estimators: 2000,max_depth: 100,learning_rate: 0.004\n",
            "Score: 14.053328845980408, n_estimators: 2000,max_depth: 100,learning_rate: 0.005\n",
            "Score: 14.070542768241495, n_estimators: 2000,max_depth: 100,learning_rate: 0.006\n",
            "Score: 14.692828179894065, n_estimators: 2000,max_depth: 100,learning_rate: 0.007\n",
            "Score: 16.049412478504877, n_estimators: 2000,max_depth: 125,learning_rate: None\n",
            "Score: 14.477603132043106, n_estimators: 2000,max_depth: 125,learning_rate: 0.004\n",
            "Score: 11.50876477786198, n_estimators: 2000,max_depth: 125,learning_rate: 0.005\n",
            "Score: 14.279250116478844, n_estimators: 2000,max_depth: 125,learning_rate: 0.006\n",
            "Score: 15.407925612205329, n_estimators: 2000,max_depth: 125,learning_rate: 0.007\n",
            "Score: 14.833506344772854, n_estimators: 2000,max_depth: 150,learning_rate: None\n",
            "Score: 14.887359467237768, n_estimators: 2000,max_depth: 150,learning_rate: 0.004\n",
            "Score: 15.559558006850017, n_estimators: 2000,max_depth: 150,learning_rate: 0.005\n",
            "Score: 14.606578244397832, n_estimators: 2000,max_depth: 150,learning_rate: 0.006\n",
            "Score: 15.025797686053759, n_estimators: 2000,max_depth: 150,learning_rate: 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best score\n",
        "model = XGBRegressor(n_estimators=2000,max_depth= 125,learning_rate=0.005,booster=\"gbtree\",objective ='reg:squarederror')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test).round()\n",
        "print(f\"RMSE: {mean_squared_error(predictions,y_test,squared=False)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5KbmhHDodtm",
        "outputId": "d1a655fa-389a-4ade-c528-20f9b83a4aff"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 9.772410142846033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_run,y_run\n",
        "model = XGBRegressor(n_estimators=2000,max_depth= 125,booster=\"gbtree\",objective ='reg:squarederror')\n",
        "model.fit(X, y)\n",
        "pickle.dump(model, open('steps_run_model.pkl', 'wb'))\n",
        "run_model = pickle.load(open('steps_run_model.pkl', 'rb'))\n",
        "predictions = run_model.predict(X).round()\n",
        "mean_squared_error(predictions,y,squared=False)"
      ],
      "metadata": {
        "id": "QttX2QpNi9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796875cb-b1a4-4f40-bc73-51828edfcb28"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_m3reBurlTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}